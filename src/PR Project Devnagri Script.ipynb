{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","from sklearn.model_selection import StratifiedKFold\n","import albumentations as A\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm as tqdm\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MEAN = [0.485, 0.456, 0.406] \n","STD = [0.229, 0.224, 0.225]\n","BATCH_SIZE = 256\n","HEIGHT = 32\n","WIDTH = 32\n","N_EPOCHS = 10\n","N_FOLDS = 5\n","N_WORKERS = 4\n","INIT_LR = 0.01\n","RANDOM_STATE = 47\n","DATASET_DIR = \"../data/\"\n","MODEL_PATH = \"../models/\"\n","N_FOLDS = 5\n","FOLD = 0\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(DATASET_DIR + \"data.csv\")\n","classes = df.character.unique()\n","\n","idx2class = {i:class_name for i, class_name in enumerate(classes)}\n","class2idx = {class_name:i for i, class_name in enumerate(classes)}\n","\n","df[\"character_id\"] = df.character.map(class2idx)\n","\n","skf = StratifiedKFold(N_FOLDS, shuffle = True, random_state = RANDOM_STATE)\n","for i_fold, (train_idx, val_idx) in enumerate(skf.split(df, df.character)):\n","    df.loc[val_idx, \"fold\"] = i_fold\n","df.fold = df.fold.astype(np.int)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Albumentations():\n","    def __init__(self, augmentations):\n","        self.augmentations  = A.Compose(augmentations)\n","    def __call__(self, image):\n","        return self.augmentations(image = image)[\"image\"]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, df, folds , mode, transform = None, transform_orig = None):\n","        df = df[df.fold.isin(folds)].reset_index(drop = True)\n","        self.images= df.drop(['character','fold', \"character_id\"], axis = 1).values\n","        self.labels = df['character_id'].values\n","        self.mode = mode\n","        self.transforms = transform\n","        self.transforms_orig = transform_orig\n","        \n","    def __len__(self):\n","        return self.images.shape[0]\n","    \n","    def __mode__(self):\n","        return self.mode\n","    \n","    def __getitem__(self, index):\n","        image = self.images[index]\n","        label = self.labels[index]\n","        image = image.reshape((HEIGHT, WIDTH))\n","        image_orig = image.astype(np.float32).copy()\n","        if self.transforms:\n","            image = self.transforms(image)\n","        if self.transforms_orig:\n","            image_orig = self.transforms_orig(image)\n","        \n","        return torch.tensor(image), torch.tensor(image_orig), torch.tensor(label)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preprocess=[\n","    \n","]\n","\n","augmentations = [\n","    A.PadIfNeeded(min_height=HEIGHT, min_width=WIDTH, border_mode=cv2.BORDER_CONSTANT, value=[255, 255, 255], always_apply=True),\n","    A.OneOf([\n","        A.ShiftScaleRotate(rotate_limit=30, border_mode=cv2.BORDER_CONSTANT, value=[0, 0, 0], mask_value=[255, 255, 255], always_apply=True),\n","    ], 0.5)\n","]\n","transforms_train = transforms.Compose([\n","    np.uint8,\n","    Albumentations(preprocess + augmentations),\n","    transforms.ToTensor(),\n","#     transforms.Normalize(mean = MEAN, std = STD)\n","])\n","\n","transforms_val = transforms.Compose([\n","    np.uint8,\n","    Albumentations(preprocess),\n","    transforms.ToTensor(),\n","#     transforms.Normalize(mean = MEAN, std = STD)\n","    \n","])\n","transforms_orig = transforms.Compose([\n","    np.uint8,\n","    Albumentations(preprocess),\n","    transforms.ToTensor(),   \n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_show = df.sample(n = 100)\n","\n","dataset_show = Dataset( df_show, [0,1,2,3],\"train\",transforms_train, transforms_orig )\n","\n","from pylab import rcParams\n","rcParams[\"figure.figsize\"] = 20,10\n","for i in range(2):\n","    f, axarr = plt.subplots(1,5)\n","    for p in range(5):\n","        idx = np.random.randint(0, len(dataset_show))\n","        img, img_orig, label = dataset_show[idx]\n","        axarr[p].imshow(img.transpose(0,1).transpose(1,2).squeeze())\n","        axarr[p].set_title(\"index: \"+ str(idx)+\" label: \" + str(label.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pretrainedmodels\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","\n","class nn_model(nn.Module):\n","    def __init__(self, pretrained):\n","        super(nn_model, self).__init__()\n","\n","        if pretrained:\n","            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained = \"imagenet\")\n","        else:\n","            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained = None)\n","\n","        self.front = nn.Conv2d(1, 3, (1, 1), stride= 1, padding = 0)\n","        self.l2 = nn.Linear(512, 47)\n","\n","    def forward(self, x):\n","        bs, _, _, _ = x.shape\n","        x = self.front(x)\n","        x = self.model.features(x)\n","        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n","        \n","        l2 = self.l2(x)\n","\n","        return l2\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def criterion(logits, targets):\n","    return nn.CrossEntropyLoss()(logits, targets)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def train_epoch(loader, optimizer):\n","    model.train()\n","    bar = tqdm(loader)\n","    train_loss = []\n","    for(data, data_orig, targets) in bar:\n","        optimizer.zero_grad()\n","        data, data_orig, targets = data.to(device), data_orig.to(device),targets.to(device)\n","        \n","        logits = model(data)\n","        loss = criterion(logits, targets)\n","        loss.backward()\n","        optimizer.step()\n","        loss_np = loss.detach().cpu().numpy()\n","        train_loss.append(loss_np)\n","        smooth_loss = sum(train_loss[-20:])/min(len(train_loss), 20)\n","\n","        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n","\n","    return train_loss\n","\n","def val_epoch(loader):\n","    model.eval()\n","    val_loss = []\n","    outputs = []\n","    LOGITS = []\n","    acc = 0\n","    pred = []\n","    with torch.no_grad():\n","        for (data, data_orig, target) in tqdm(loader):\n","            data, data_orig, target = data.to(device), data_orig.to(device), target.to(device)\n","            logits = model(data)\n","            loss = criterion(logits, target)\n","            pred = nn.Softmax(logits).argmax(1).detach()\n","            outputs.append(pred)\n","            acc += (target == pred).sum().detach().cpu().numpy()\n","            if get_output:\n","                LOGITS.append(logits)\n","            val_loss.append(loss.cpu().numpy())\n","        val_loss = np.mean(val_loss)\n","        acc /= len(dataset_valid)\n","\n","    return val_loss, acc, score\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["for i in range(N_FOLDS):\n","    print(df[df.fold == i].character_id.value_counts())"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["n_folds = N_FOLDS\n","record = [{'train_loss': [], 'val_loss': [], \"score\": []} for x in range(n_folds)]\n","\n","fold = FOLD\n","i_fold = fold\n","folds = [i for i in range(n_folds)]\n","train_idx, valid_idx = np.where((df['fold'] != i_fold))[0], np.where((df['fold'] == i_fold))[0]\n","\n","train_folds = []\n","val_folds = []\n","for i in range(n_folds):\n","    if i == fold:\n","        val_folds.append(i)\n","    else:\n","        train_folds.append(i)\n","\n","dataset_train = Dataset( df, train_folds,\"train\",transforms_train, transforms_orig )\n","\n","dataset_valid = Dataset( df, val_folds ,\"val\",transforms_val, transforms_orig )\n","\n","train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True,num_workers=0)\n","valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=False, sampler=None, num_workers=0)\n","\n","model = nn_model(pretrained= True)\n","model = model.to(device)\n","\n","max_acc = 0\n","model_file = f\"{MODEL_PATH}resnet34_pretrained_best_fold_{i_fold}.pth\"\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = INIT_LR)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["for epoch in range(1, N_EPOCHS+1):\n","    print(time.ctime(), 'Epoch:', epoch)\n"," \n","    train_loss = train_epoch(train_loader, optimizer)\n","    val_loss, acc = val_epoch(valid_loader)\n","\n","    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}'\n","    \n","    print(content)\n","    with open(f\"log_resnet34.txt\", \"a\") as appender:\n","        appender.write(content + \"\\n\")\n","    \n","    if (epoch) % 125==0 or (epoch+1)%120 == 0:\n","        print(f\"Saving model on epoch {epoch}\")\n","        torch.save(model.state_dict(), f'{MODEL_PATH}resnet34_{epoch}_fold{i_fold}.pth')\n","\n","    if acc > max_acc:\n","        max_acc = acc\n","        print('acc ({:.6f} --> {:.6f}).  Saving model ...'.format(max_acc, acc))\n","        torch.save(model.state_dict(), model_file)\n","\n","torch.save(model.state_dict(), os.path.join(f'resnet34_model_fold{i_fold}.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.7.4-final","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}